{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import * \n",
    "\n",
    "data_folder = \"../data/zw3d-joinable-dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6462/6462 [00:32<00:00, 198.82it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_parts():\n",
    "    prefix = \"part\"\n",
    "    part_files = []\n",
    "\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.startswith(prefix) and filename.endswith(\".json\"):\n",
    "            part_files.append(filename)\n",
    "\n",
    "    part_map = {}\n",
    "    for part_file in tqdm(part_files):\n",
    "        with open(data_folder + part_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        part_name, _ = part_file.split(\".\")\n",
    "        part_map[part_name] = data\n",
    "    return part_map\n",
    "\n",
    "part_map = read_parts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:00<00:00, 13636.80it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data(split):\n",
    "    with open(data_folder + \"train_test.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        train_test_splits = json.load(file)\n",
    "\n",
    "    joint_set_list = []\n",
    "    for filename in tqdm(train_test_splits[split]):\n",
    "        with open(data_folder + filename + \".json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            joint_set = json.load(file)\n",
    "        joint_set_list.append(joint_set)\n",
    "    return joint_set_list\n",
    "\n",
    "test_data = load_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import heapq\n",
    "\n",
    "def find_nodes_with_radius(part):\n",
    "    radius_to_nodes = defaultdict(list)\n",
    "    for i, node in enumerate(part[\"nodes\"]):\n",
    "        if \"surface_type\" in node and node[\"surface_type\"] in \"CylinderSurfaceType\":\n",
    "            rounded_radius = round(node[\"param_1\"], 1)\n",
    "            radius_to_nodes[rounded_radius].append(i)\n",
    "        # if \"curve_type\" in node and node[\"curve_type\"] in (\"Arc3DCurveType\", \"Circle3DCurveType\"):\n",
    "        #     rounded_radius = round(node[\"radius\"], 1)\n",
    "        #     radius_to_nodes[rounded_radius].append(i)\n",
    "    return radius_to_nodes\n",
    "\n",
    "def find_plane_nodes(part):\n",
    "    plane_list = []\n",
    "    for i, node in enumerate(part[\"nodes\"]):\n",
    "        if \"surface_type\" in node and node[\"surface_type\"] == \"PlaneSurfaceType\":\n",
    "            plane_list.append((node[\"area\"], i))\n",
    "    return plane_list\n",
    "\n",
    "def predict(joint_set, result_num=50):\n",
    "    res = []\n",
    "\n",
    "    # 如果有半径相似的实体，加入结果集\n",
    "    part_1, part_2 = part_map[joint_set[\"body_one\"]], part_map[joint_set[\"body_two\"]]\n",
    "    radius_to_nodes1 = find_nodes_with_radius(part_1)\n",
    "    radius_to_nodes2 = find_nodes_with_radius(part_2)\n",
    "\n",
    "    # closest_pairs = ([], [])\n",
    "    # if radius_to_nodes1 and radius_to_nodes2:\n",
    "    #     min_diff = float(\"inf\")\n",
    "    #     for radius1, radius2 in product(radius_to_nodes1.keys(), radius_to_nodes2.keys()):\n",
    "    #         diff = abs(radius1 - radius2)\n",
    "    #         if diff < min_diff:\n",
    "    #             min_diff = diff\n",
    "    #             closest_pairs = (radius_to_nodes1[radius1], radius_to_nodes2[radius2])\n",
    "    # for id1 in closest_pairs[0]:\n",
    "    #     for id2 in closest_pairs[1]:\n",
    "    #         res.append((id1, id2))\n",
    "    #         if len(res) == result_num:\n",
    "    #             return res\n",
    "    \n",
    "    top_3_min_diff = []\n",
    "    if radius_to_nodes1 and radius_to_nodes2:\n",
    "        for radius1, radius2 in product(radius_to_nodes1.keys(), radius_to_nodes2.keys()):\n",
    "            radius_nodes1_nodes2 = (-abs(radius1 - radius2), radius_to_nodes1[radius1], radius_to_nodes2[radius2])\n",
    "            heapq.heappush(top_3_min_diff, radius_nodes1_nodes2)\n",
    "            if len(top_3_min_diff) > 3:\n",
    "                heapq.heappop(top_3_min_diff)\n",
    "\n",
    "    top_3_min_diff.sort(key=lambda x: -x[0])\n",
    "    for _, nodes1, nodes2 in top_3_min_diff:\n",
    "        res.append((nodes1[0], nodes2[0]))\n",
    "    \n",
    "    \n",
    "    # 按从大到小的顺序找一对平面，加入结果集\n",
    "    plane_list1 = find_plane_nodes(part_1)\n",
    "    plane_list2 = find_plane_nodes(part_2)\n",
    "    plane_pair_list = []\n",
    "    for area1, id1 in plane_list1:\n",
    "        for area2, id2 in plane_list2:\n",
    "            plane_pair_list.append((area1 + area2, id1, id2))\n",
    "            \n",
    "    plane_pair_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    for _, id1, id2 in plane_pair_list:\n",
    "        res.append((id1, id2))\n",
    "        if len(res) == result_num:\n",
    "            return res\n",
    "\n",
    "    return res\n",
    "\n",
    "def load_label(joint_set):\n",
    "    part_1, part_2 = joint_set[\"body_one\"], joint_set[\"body_two\"]\n",
    "    labels = []\n",
    "    for joint in joint_set[\"joints\"]:\n",
    "        id_set1, id_set2 = set(), set()\n",
    "        geom1 = joint[\"geometry_or_origin_one\"]\n",
    "        geom2 = joint[\"geometry_or_origin_two\"]\n",
    "        entity1 = geom1[\"entity_one\"]\n",
    "        entity2 = geom2[\"entity_one\"]\n",
    "        id1 = entity1[\"index\"] \n",
    "        id2 = entity2[\"index\"]\n",
    "        if \"surface_type\" not in entity1:\n",
    "            id1 += part_map[part_1][\"properties\"][\"face_count\"]\n",
    "        if \"surface_type\" not in entity2:\n",
    "            id2 += part_map[part_2][\"properties\"][\"face_count\"]\n",
    "        id_set1.add(id1)\n",
    "        id_set2.add(id2)\n",
    "\n",
    "        for eq in geom1[\"entity_one_equivalents\"]:\n",
    "            id = eq[\"index\"] \n",
    "            if \"surface_type\" not in eq:\n",
    "                id += part_map[part_1][\"properties\"][\"face_count\"]\n",
    "            id_set1.add(id)\n",
    "        for eq in geom2[\"entity_one_equivalents\"]:\n",
    "            id = eq[\"index\"] \n",
    "            if \"surface_type\" not in eq:\n",
    "                id += part_map[part_2][\"properties\"][\"face_count\"]\n",
    "            id_set2.add(id)\n",
    "        labels.append((joint[\"joint_type\"], id_set1, id_set2))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1:\t 0.168981\n",
      "Top 5:\t 0.337963\n",
      "Top 50:\t 0.683642\n"
     ]
    }
   ],
   "source": [
    "def test(data_set):\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "    top50 = 0\n",
    "    for data in data_set:\n",
    "        preds = predict(data)\n",
    "        labels = load_label(data)\n",
    "        for i, pred in enumerate(preds):\n",
    "            flag = False\n",
    "            for label in labels:\n",
    "                if pred[0] in label[1] and pred[1] in label[2]:\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                top50 += 1\n",
    "                if i < 5:\n",
    "                    top5 += 1\n",
    "                if i == 0:\n",
    "                    top1 += 1\n",
    "                break\n",
    "    print(\"Top 1:\\t %f\" % (top1 / len(data_set)))\n",
    "    print(\"Top 5:\\t %f\" % (top5 / len(data_set)))\n",
    "    print(\"Top 50:\\t %f\" % (top50 / len(data_set)))\n",
    "    \n",
    "test(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joinable_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
