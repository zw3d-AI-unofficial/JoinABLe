{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Prediction Viewer\n",
    "Visualize predictions for joint entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fusiqiao/miniconda3/envs/joinable_env/lib/python3.7/site-packages/pytorch_lightning/metrics/__init__.py:44: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  \"`pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "\n",
    "root_dir = Path().resolve().parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "from joint.joint_prediction_set import JointPredictionSet\n",
    "from joint.joint_environment import JointEnvironment\n",
    "from datasets.joint_graph_dataset import JointGraphDataset\n",
    "from train import JointPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Network\n",
    "Load a pretrained checkpoint to use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(checkpoint_file):\n",
    "    \"\"\"Load the network\"\"\"\n",
    "    if not checkpoint_file.exists():\n",
    "        print(\"Checkpoint file does not exist\")\n",
    "        return None\n",
    "    model = JointPrediction.load_from_checkpoint(\n",
    "        checkpoint_file,\n",
    "        map_location=torch.device(\"cpu\")  # Just use the CPU\n",
    "    )\n",
    "    return model\n",
    "\n",
    "checkpoint_file = root_dir / \"pretrained/paper/last_run_0.ckpt\"\n",
    "model = load_network(checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Load the dataset and create an instance of the JointPredictionSet class\n",
    "We assume that the joint json and mesh part files are in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cache loaded from: /home/fusiqiao/code/JoinABLe/data/tester/val.pickle\n"
     ]
    }
   ],
   "source": [
    "# Change to point to the Fusion 360 Gallery joint dataset\n",
    "# this directory should contain the joint json and obj part files\n",
    "data_dir = root_dir / \"data/tester\"\n",
    "# data_dir = Path(\"C:/Users/pc/Desktop/test1\")\n",
    "\n",
    "dataset = JointGraphDataset(\n",
    "    root_dir=data_dir,\n",
    "    split=\"val\",\n",
    "    label_scheme=\"Joint,JointEquivalent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Data sample in the dataset we want to visualize\n",
    "# index = randint(0, len(dataset))\n",
    "# print(\"index = \", index)\n",
    "index = 0\n",
    "\n",
    "# Graphs for part one and two, and the densely connected joint graph\n",
    "g1, g2, joint_graph = dataset[index]\n",
    "# The joint file json\n",
    "joint_file = data_dir / dataset.files[index]\n",
    "\n",
    "# Load the prediction data\n",
    "jps = JointPredictionSet(\n",
    "    joint_file,\n",
    "    g1, g2, joint_graph,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the Top-1 Prediction\n",
    "We use the JointEnvironment to calculate the transform that aligns the two parts together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b15be806d3a44b989ebe3860918f193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.056820…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the transform to move body1, to align with the static body2\n",
    "# using default parameters, i.e. no offset, rotation, or flip\n",
    "transform = JointEnvironment.get_transform_from_parameters(\n",
    "    jps,\n",
    "    prediction_index=0,  # Top-1 prediction\n",
    "    offset=0,\n",
    "    rotation_in_degrees=0,\n",
    "    flip=False\n",
    ")\n",
    "\n",
    "# Render the meshes to visualize\n",
    "v, f, c, e, n, ni = jps.get_meshes(\n",
    "    apply_transform=True,\n",
    "    body_one_transform= jps.get_transform(body=2) @ transform,\n",
    "    show_joint_entity_colors=False,\n",
    "    show_joint_equivalent_colors=False,\n",
    "    return_vertex_normals=True\n",
    ")\n",
    "p = mp.plot(v, f, c=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Entity Predictions\n",
    "Show the predictions as pink highlights on the joint bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d8c2e8b23e42418a2f0c5e158ed7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.056820…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "body = 1\n",
    "v1, f1, _, _ = jps.get_mesh(\n",
    "    body=body,\n",
    "    apply_transform=False,\n",
    "    show_joint_entity_colors=False,\n",
    "    show_joint_equivalent_colors=False\n",
    ")\n",
    "c1, e1 = jps.get_joint_predictions(body=body, limit=1)\n",
    "p = mp.plot(v1, f1, c=c1, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "# TODO: Add support for edge colors\n",
    "if e1 is not None:\n",
    "    p.add_edges(v1, e1, shading={\"line_color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8801a8aaf05476fba61d50629431fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.057930…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "body = 2\n",
    "v2, f2, _, _ = jps.get_mesh(\n",
    "    body=body,\n",
    "    apply_transform=False,\n",
    "    show_joint_entity_colors=False,\n",
    "    show_joint_equivalent_colors=False\n",
    ")\n",
    "c2, e2 = jps.get_joint_predictions(body=body, limit=1)\n",
    "p = mp.plot(v2, f2, c=c2, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "# TODO: Add support for edge colors\n",
    "if e2 is not None:\n",
    "    p.add_edges(v2, e2, shading={\"line_color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Entity Axes\n",
    "Show the joint axes derived from the predicted B-Rep faces/edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5705dd87104d9da09f0e17a84dfb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.056820…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = 1\n",
    "p = mp.plot(v1, f1, c=c1, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "if e1 is not None:\n",
    "    p.add_edges(v1, e1, shading={\"line_color\": \"red\"})\n",
    "start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, limit=1)\n",
    "# start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, show_index=0)\n",
    "p.add_lines(start_pts, end_pts, shading={\"line_color\": \"green\"})\n",
    "p.add_points(start_pts, shading={\"point_color\": \"green\", \"point_size\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c2c84b58da413c902b7dcd1bc6d560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(-0.057930…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = 2\n",
    "p = mp.plot(v2, f2, c=c2, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "if e2 is not None:\n",
    "    p.add_edges(v2, e2, shading={\"line_color\": \"red\"})\n",
    "start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, limit=1)\n",
    "# start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, index=0)\n",
    "p.add_lines(start_pts, end_pts, shading={\"line_color\": \"green\"})\n",
    "p.add_points(start_pts, shading={\"point_color\": \"green\", \"point_size\": 1})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bf1c82db291c90cc4874b8785149ede8d32de9ceb77e89bfd1ded6bd42ea729"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
