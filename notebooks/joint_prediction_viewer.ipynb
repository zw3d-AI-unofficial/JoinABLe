{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Prediction Viewer\n",
    "Visualize predictions for joint entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "\n",
    "root_dir = Path().resolve().parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "from joint.joint_prediction_set import JointPredictionSet\n",
    "from joint.joint_environment import JointEnvironment\n",
    "from datasets.joint_graph_dataset import JointGraphDataset\n",
    "from train import JointPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Network\n",
    "Load a pretrained checkpoint to use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(checkpoint_file):\n",
    "    \"\"\"Load the network\"\"\"\n",
    "    if not checkpoint_file.exists():\n",
    "        print(\"Checkpoint file does not exist\")\n",
    "        return None\n",
    "    model = JointPrediction.load_from_checkpoint(\n",
    "        checkpoint_file,\n",
    "        map_location=torch.device(\"cpu\")  # Just use the CPU\n",
    "    )\n",
    "    return model\n",
    "\n",
    "checkpoint_file = root_dir / \"results/00_baseline/last.ckpt\"\n",
    "model = load_network(checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Load the dataset and create an instance of the JointPredictionSet class\n",
    "We assume that the joint json and mesh part files are in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cache deleted from: /home/fusiqiao/Projects/JoinABLe/data/test/train.pickle\n",
      "Using new train test split\n",
      "Loading 38 train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:03<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total graph load time: 3.613908529281616 sec\n",
      "Skipped: 0 files\n",
      "Done loading 38 files\n",
      "Data cache written to: /home/fusiqiao/Projects/JoinABLe/data/test/train.pickle\n"
     ]
    }
   ],
   "source": [
    "# Change to point to the Fusion 360 Gallery joint dataset\n",
    "# this directory should contain the joint json and obj part files\n",
    "data_dir = root_dir / \"data/test\"\n",
    "dataset = JointGraphDataset(data_dir, label_scheme=\"Joint,JointEquivalent\", delete_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Data sample in the dataset we want to visualize\n",
    "# index = randint(0, len(dataset))\n",
    "# print(\"index = \", index)\n",
    "index = 0\n",
    "\n",
    "# Graphs for part one and two, and the densely connected joint graph\n",
    "g1, g2, joint_graph = dataset[index]\n",
    "# The joint file json\n",
    "joint_file = data_dir / dataset.files[index]\n",
    "\n",
    "# Load the prediction data\n",
    "jps = JointPredictionSet(\n",
    "    joint_file,\n",
    "    g1, g2, joint_graph,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the Top-1 Prediction\n",
    "We use the JointEnvironment to calculate the transform that aligns the two parts together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transform to move body1, to align with the static body2\n",
    "# using default parameters, i.e. no offset, rotation, or flip\n",
    "transform = JointEnvironment.get_transform_from_parameters(\n",
    "    jps,\n",
    "    prediction_index=0,  # Top-1 prediction\n",
    "    offset=0,\n",
    "    rotation_in_degrees=0,\n",
    "    flip=False\n",
    ")\n",
    "\n",
    "# Render the meshes to visualize\n",
    "v, f, c, e, n, ni = jps.get_meshes(\n",
    "    apply_transform=True,\n",
    "    body_one_transform= jps.get_transform(body=2) @ transform,\n",
    "    show_joint_entity_colors=False,\n",
    "    show_joint_equivalent_colors=False,\n",
    "    return_vertex_normals=True\n",
    ")\n",
    "p = mp.plot(v, f, c=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Entity Predictions\n",
    "Show the predictions as pink highlights on the joint bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = 1\n",
    "v1, f1, _, _ = jps.get_mesh(\n",
    "    body=body,\n",
    "    apply_transform=False,\n",
    "    show_joint_entity_colors=False,\n",
    "    show_joint_equivalent_colors=False\n",
    ")\n",
    "c1, e1 = jps.get_joint_predictions(body=body)\n",
    "p = mp.plot(v1, f1, c=c1, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "# TODO: Add support for edge colors\n",
    "if e1 is not None:\n",
    "    p.add_edges(v1, e1, shading={\"line_color\": \"red\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = 2\n",
    "v2, f2, _, _ = jps.get_mesh(\n",
    "    body=body,\n",
    "    apply_transform=False,\n",
    "    show_joint_entity_colors=False,\n",
    "    show_joint_equivalent_colors=False\n",
    ")\n",
    "c2, e2 = jps.get_joint_predictions(body=body)\n",
    "p = mp.plot(v2, f2, c=c2, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "# TODO: Add support for edge colors\n",
    "if e2 is not None:\n",
    "    p.add_edges(v2, e2, shading={\"line_color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Entity Axes\n",
    "Show the joint axes derived from the predicted B-Rep faces/edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = 1\n",
    "p = mp.plot(v1, f1, c=c1, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "if e1 is not None:\n",
    "    p.add_edges(v1, e1, shading={\"line_color\": \"red\"})\n",
    "start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, limit=1)\n",
    "# start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, show_index=0)\n",
    "p.add_lines(start_pts, end_pts, shading={\"line_color\": \"green\"})\n",
    "p.add_points(start_pts, shading={\"point_color\": \"green\", \"point_size\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = 2\n",
    "p = mp.plot(v2, f2, c=c2, shading={\"colormap\": \"cool\", \"normalize\": [0, 1]})\n",
    "if e2 is not None:\n",
    "    p.add_edges(v2, e2, shading={\"line_color\": \"red\"})\n",
    "start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, limit=1)\n",
    "# start_pts, end_pts = jps.get_joint_prediction_axis_lines(body=body, index=0)\n",
    "p.add_lines(start_pts, end_pts, shading={\"line_color\": \"green\"})\n",
    "p.add_points(start_pts, shading={\"point_color\": \"green\", \"point_size\": 1})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bf1c82db291c90cc4874b8785149ede8d32de9ceb77e89bfd1ded6bd42ea729"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
